{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCity Schools Analysis\n",
    "\n",
    "#-Overall summary: This notebook contains a high level snapshot of district wide descriptive statistics relating to students' educational outcomes (testing scores and passing rates) and a more granular, per school breakdown of the same kind. Included in the analysis are number of students, overall budget, per student budgets, math and reading test scores, the percentage of student passing math and reading, and the overall passing rate of the students. This data is broken down into a school size, per student budget, and school type analyses. Also included is a breakdown of per grade level educational performance for each school in the district and a list of the top and bottom performing schools by overall passing rates.\n",
    "\n",
    "A quick summary of the data shows that charter schools are outperforming district schools in both reading and math testing and passing rates independent of per student spending. Institution size my also be influencing student outcomes independent of institution type.\n",
    "  \n",
    "#---Key conclusion #1: Per student spending does not equate to better educational outcomes. On average (and perhaps paradoxically), schools with lower per student budgets have better educational outcomes in both testing scores and passing rates. To solve problems related to substandard educational outcomes, simply spending more money per student may not be the answer. A deeper dive into budgetary issues, such as a more detailed analysis of on what and how schools are spending their budgets, may give more insights into if and when budgetary considerations can influence educational outcomes. It appears that how schools spend their budgets may be more important than the total amount spent (or budget may only have a threshold type effect that we can't see in the current dataset).\n",
    "\n",
    "#---Key conclusion #2: Superficially, it appears that charter schools have better educational outcomes than district schools. However, we have a serious conflating factor in that charter schools on average are much smaller than district schools (all district schools are classified as \"large\", while only one charter school is considered \"large\"). Thus, if we were to ignore school type, our data would also suggest an inverse correlation between test scores and school size (smaller instiutions tend to have higher test scores). While we can't be certain from the current analysis, this may be due to factors such as learning-beneficial student to teacher ratios, smaller class sizes, or other factors that show positive educational outcomes in relation to the size of the institution. Taken to the extreme, it may suggest that districts would benefit from building more schools in order to pare down insitution sizes. Our conflation problem, however, makes conclusions difficult to draw. The single large charter school in our dataset does suggest that institution type may be more important than instiution size, but we would need more data representing a wider variety of school sizes by type to draw more definitive conslusions. Our conflation problem does inform further analysis with more district/charter schools of a range of sizes to tease out the specific factors that are correlated with instution size/type that may influence educational outcomes.\n",
    "\n",
    "#---Key conclusion #3: To help close the overall gap in student performance between charter and district schools, it would appear best to focus effort on improving math performance in district schools, given the larger delta between test scores and passing rates in math between charter and district schools compared to reading scores and passing rates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# File to Load (Remember to Change These)\n",
    "school_data_to_load = Path(\"Resources/schools_complete.csv\")\n",
    "student_data_to_load = Path(\"Resources/students_complete.csv\")\n",
    "\n",
    "# Read School and Student Data File and store into Pandas DataFrames\n",
    "school_data = pd.read_csv(school_data_to_load)\n",
    "student_data = pd.read_csv(student_data_to_load)\n",
    "\n",
    "# Combine the data into a single dataset.  \n",
    "school_data_complete = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "school_data_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total number of unique schools\n",
    "school_count = school_data_complete['school_name'].nunique()\n",
    "school_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of students\n",
    "student_count = school_data_complete['student_name'].count()\n",
    "student_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total budget\n",
    "total_budget = school_data_complete.drop_duplicates(subset='school_name')['budget'].sum()\n",
    "total_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) math score\n",
    "average_math_score = school_data_complete['math_score'].mean()\n",
    "average_math_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) reading score\n",
    "average_reading_score = school_data_complete['reading_score'].mean()\n",
    "average_reading_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students who passed math (math scores greather than or equal to 70)\n",
    "passing_math_count = school_data_complete[(school_data_complete[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
    "passing_math_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of students who passed reading (hint: look at how the math percentage was calculated)  \n",
    "passing_reading_count = school_data_complete[(school_data_complete[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
    "passing_reading_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students that passed math and reading\n",
    "passing_math_reading_count = school_data_complete[\n",
    "    (school_data_complete[\"math_score\"] >= 70) & (school_data_complete[\"reading_score\"] >= 70)\n",
    "].count()[\"student_name\"]\n",
    "overall_passing_rate = passing_math_reading_count /  float(student_count) * 100\n",
    "overall_passing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-level snapshot of the district's key metrics in a DataFrame\n",
    "district_summary = pd.DataFrame({'Total Schools': school_count,'Total Students': student_count,'Total Budget': total_budget,'Average Math Score': average_math_score,'Average Reading Score': average_reading_score,'% Passing Math': passing_math_percentage,'% Passing Reading': passing_reading_percentage,'% Overall Passing': overall_passing_rate}, index=[0])\n",
    "\n",
    "# Formatting\n",
    "district_summary['Total Students'] = district_summary['Total Students'].map('{:,}'.format)\n",
    "district_summary['Total Budget'] = district_summary['Total Budget'].map('${:,.2f}'.format)\n",
    "\n",
    "# Display the DataFrame\n",
    "district_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to select all of the school types\n",
    "school_types = school_data_complete.drop_duplicates(subset = 'school_name').set_index('school_name')['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total student count per school\n",
    "per_school_counts = school_data_complete.drop_duplicates(subset = 'school_name').set_index('school_name')['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total school budget and per capita spending per school\n",
    "per_school_budget = school_data_complete.drop_duplicates(subset = 'school_name').set_index('school_name')['budget']\n",
    "per_school_capita = per_school_budget / per_school_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average test scores per school\n",
    "per_school_math = school_data_complete.groupby('school_name')['math_score'].mean()\n",
    "per_school_reading = school_data_complete.groupby('school_name')['reading_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of students per school with math scores of 70 or higher\n",
    "students_passing_math = school_data_complete[(school_data_complete[\"math_score\"] >= 70)]\n",
    "school_students_passing_math = students_passing_math.groupby('school_name')[\"student_name\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of students per school with reading scores of 70 or higher\n",
    "students_passing_reading = school_data_complete[(school_data_complete[\"reading_score\"] >= 70)]\n",
    "school_students_passing_reading = students_passing_reading.groupby('school_name')[\"student_name\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the number of students per school that passed both math and reading with scores of 70 or higher\n",
    "students_passing_math_and_reading = school_data_complete[\n",
    "    (school_data_complete['reading_score'] >= 70) & (school_data_complete['math_score'] >= 70)\n",
    "]\n",
    "school_students_passing_math_and_reading = students_passing_math_and_reading.groupby(['school_name']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the passing rates\n",
    "per_school_passing_math = school_students_passing_math / per_school_counts * 100\n",
    "per_school_passing_reading = school_students_passing_reading / per_school_counts * 100\n",
    "overall_passing_rate = school_students_passing_math_and_reading / per_school_counts * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame called `per_school_summary` with columns for the calculations above.\n",
    "per_school_summary = pd.concat([school_types, per_school_counts, per_school_budget, per_school_capita, per_school_math, per_school_reading, per_school_passing_math, per_school_passing_reading, overall_passing_rate], axis=1, join='outer', keys=['School Type','Total Students', 'Total School Budget','Per Student Budget','Average Math Score', 'Average Reading Score','% Passing Math', '% Passing Reading','% Overall Passing'])\n",
    "\n",
    "# Formatting\n",
    "per_school_summary[\"Total School Budget\"] = per_school_summary[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
    "per_school_summary[\"Per Student Budget\"] = per_school_summary[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "per_school_summary = per_school_summary.sort_values('school_name')\n",
    "per_school_summary.index.name = None\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest-Performing Schools (by % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in descending order and display the top 5 rows.\n",
    "top_schools = per_school_summary.sort_values('% Overall Passing', ascending=False)\n",
    "top_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Performing Schools (By % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in ascending order and display the top 5 rows.\n",
    "bottom_schools = per_school_summary.sort_values('% Overall Passing', ascending=True)\n",
    "bottom_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Scores by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by `school_name` and take the mean of the `math_score` column for each.\n",
    "ninth_grader_math_scores = ninth_graders.groupby('school_name')['math_score'].mean()\n",
    "tenth_grader_math_scores = tenth_graders.groupby('school_name')['math_score'].mean()\n",
    "eleventh_grader_math_scores = eleventh_graders.groupby('school_name')['math_score'].mean()\n",
    "twelfth_grader_math_scores = twelfth_graders.groupby('school_name')['math_score'].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "math_scores_by_grade_columns = ['9th','10th','11th','12th']\n",
    "math_scores_by_grade = pd.concat([ninth_grader_math_scores, tenth_grader_math_scores, eleventh_grader_math_scores, twelfth_grader_math_scores], keys=math_scores_by_grade_columns,axis = 1)\n",
    "\n",
    "\n",
    "# Minor data wrangling\n",
    "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "math_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "math_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Score by Grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by `school_name` and take the mean of the the `reading_score` column for each.\n",
    "ninth_grader_reading_scores = ninth_graders.groupby('school_name')['reading_score'].mean()\n",
    "tenth_grader_reading_scores = tenth_graders.groupby('school_name')['reading_score'].mean()\n",
    "eleventh_grader_reading_scores = eleventh_graders.groupby('school_name')['reading_score'].mean()\n",
    "twelfth_grader_reading_scores = twelfth_graders.groupby('school_name')['reading_score'].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `reading_scores_by_grade`\n",
    "\n",
    "reading_scores_by_grade_columns = ['9th','10th','11th','12th']\n",
    "reading_scores_by_grade = pd.concat([ninth_grader_reading_scores, tenth_grader_reading_scores, eleventh_grader_reading_scores, twelfth_grader_reading_scores], keys=reading_scores_by_grade_columns,axis = 1)\n",
    "\n",
    "# Minor data wrangling\n",
    "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "reading_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "reading_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins \n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = ['<$585','$585-630','$630-645','$645-680']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the school summary since it has the \"Per Student Budget\" \n",
    "school_spending_df = per_school_summary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use `pd.cut` to categorize spending based on the bins.\n",
    "\n",
    "#convert 'Per Student Budget' values from the previous string formatting back into integers\n",
    "school_spending_df['Per Student Budget'] = school_spending_df['Per Student Budget'].str.replace('[^\\d.]', '', regex=True).astype(float).astype(int)\n",
    "\n",
    "school_spending_df[\"Spending Ranges (Per Student)\"] = pd.cut(school_spending_df['Per Student Budget'], bins=spending_bins, labels=labels)\n",
    "\n",
    "#reformat 'Per Student Budget' values and print out 'school_spending_df'\n",
    "school_spending_df[\"Per Student Budget\"] = school_spending_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "school_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate averages for the desired columns. \n",
    "spending_math_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Math Score\"].mean()\n",
    "spending_reading_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Reading Score\"].mean()\n",
    "spending_passing_math = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Math\"].mean()\n",
    "spending_passing_reading = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Reading\"].mean()\n",
    "overall_passing_spending = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into DataFrame\n",
    "spending_summary = pd.concat([spending_math_scores, spending_reading_scores, spending_passing_math, spending_passing_reading, overall_passing_spending], axis = 1)\n",
    "\n",
    "# Display results\n",
    "spending_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins.\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Categorize the spending based on the bins\n",
    "# Use `pd.cut` on the \"Total Students\" column of the `per_school_summary` DataFrame.\n",
    "\n",
    "per_school_summary[\"School Size\"] = pd.cut(per_school_summary['Total Students'], size_bins, labels=labels)\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for the desired columns. \n",
    "size_math_scores = per_school_summary.groupby([\"School Size\"])[\"Average Math Score\"].mean()\n",
    "size_reading_scores = per_school_summary.groupby([\"School Size\"])[\"Average Reading Score\"].mean()\n",
    "size_passing_math = per_school_summary.groupby([\"School Size\"])[\"% Passing Math\"].mean()\n",
    "size_passing_reading = per_school_summary.groupby([\"School Size\"])[\"% Passing Reading\"].mean()\n",
    "size_overall_passing = per_school_summary.groupby([\"School Size\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame called `size_summary` that breaks down school performance based on school size (small, medium, or large).\n",
    "# Use the scores above to create a new DataFrame called `size_summary`\n",
    "\n",
    "size_summary = pd.concat([size_math_scores, size_reading_scores, size_passing_math, size_passing_reading, size_overall_passing], axis = 1)\n",
    "\n",
    "# Display results\n",
    "size_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the per_school_summary DataFrame by \"School Type\" and average the results.\n",
    "average_math_score_by_type = per_school_summary.groupby([\"School Type\"])[\"Average Math Score\"].mean()\n",
    "average_reading_score_by_type = per_school_summary.groupby([\"School Type\"])[\"Average Reading Score\"].mean()\n",
    "average_percent_passing_math_by_type = per_school_summary.groupby([\"School Type\"])[\"% Passing Math\"].mean()\n",
    "average_percent_passing_reading_by_type = per_school_summary.groupby([\"School Type\"])[\"% Passing Reading\"].mean()\n",
    "average_percent_overall_passing_by_type = per_school_summary.groupby([\"School Type\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the new data by type into a DataFrame called `type_summary`\n",
    "type_summary = pd.concat([average_math_score_by_type, average_reading_score_by_type, average_percent_passing_math_by_type, average_percent_passing_reading_by_type, average_percent_overall_passing_by_type], axis = 1)\n",
    "\n",
    "# Display results\n",
    "type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5384d77d82de63fd599f73e77f9ec786e7719288bf80a29ec0288c670ac3cf32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
